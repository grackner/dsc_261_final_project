{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grackner/dsc_261_final_project/blob/main/phi_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I52_Ek1HQG8d"
      },
      "source": [
        "## Phi Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWzYJkccQ4n8"
      },
      "source": [
        "url: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct?library=transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH5kEhSCPpbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJTNWrbaPsbT"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True, dtype='float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsIe59dEZtJN"
      },
      "outputs": [],
      "source": [
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSdKlKFDP5K8"
      },
      "outputs": [],
      "source": [
        "# Test inference\n",
        "messages =[\n",
        "    {\"role\": \"user\", \"content\": \"Who is Michael Jordan?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        ").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=100, use_cache=False)\n",
        "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_9B5bi1c1J5"
      },
      "outputs": [],
      "source": [
        "# Create test dataset\n",
        "phi_df = pd.DataFrame(columns=['uuid', 'topic', 'generated_article'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sMHL5fCxsCG"
      },
      "outputs": [],
      "source": [
        "topics = ['US - Crime + Justice', 'World - Africa', 'World - Americas', 'World - Asia', 'World - Australia', 'World - China', 'World - Europe', 'World - India', 'World - Middle East', 'World - United Kingdom',\n",
        "          'World - India', 'World - Middle East', 'World - United Kingdom', 'Politics - CNN Polls', 'Politics - Elections', 'Business - Tech', 'Business - Media', 'Business - Markets',\n",
        "          'Business - Pre-markets', 'Business - After-Hours', 'Business - Investing', 'Business - Markets Now', 'Health - Fitness', 'Health - Food', 'Health - Sleep', 'Health - Mindfulness',\n",
        "          'Health - Relationships', 'Entertainment - Movies', 'Entertainment - Television', 'Entertainment - Celebrity', 'Tech - Innovate', 'Tech - Foreseeable Future', 'Tech - Innovative Cities',\n",
        "          'Style - Arts', 'Style - Design', 'Style - Fashion', 'Style - Architecture', 'Style - Luxury', 'Style - Beauty', 'Travel - Destinations', 'Travel - Food & Drink', 'Travel - Lodging and Hotels',\n",
        "          'Travel - News', 'Sports - Pro Football', 'Sports - College Football', 'Sports - Basketball', 'Sports - Baseball', 'Sports - Soccer', 'Sports - Olympics', 'Sports - Hockey',\n",
        "          'Science - Space', 'Science - Life', 'Science - Medicine', 'Science - Climate', 'Science - Solutions', 'Science - Weather']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUYcCh6YlFSk"
      },
      "outputs": [],
      "source": [
        "def generate_article(topic):\n",
        "  messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Write a full news article in the style of CNN or DailyMail.\n",
        "                    The story should sound realistic, factual, and human-written.\n",
        "                    Use natural journalistic language with short and medium-length sentences.\n",
        "                    Start with a strong lead paragraph summarizing who, what, where, and when.\n",
        "                    Then expand with quotes, context, background, and a final paragraph about next steps or reactions.\n",
        "                    Include realistic numbers, dates, and locations.\n",
        "                    The article should be about {topic}.\n",
        "                    Add 1–3 short quotes attributed to plausible people (officials, witnesses, or experts).\n",
        "                    Use neutral tone — no opinions, exaggeration, or bullet points.\n",
        "                    Output only the article text (no headline, no lists, no explanation, no “to summarize”).\n",
        "                    End cleanly after several paragraphs.\n",
        "                  \"\"\"\n",
        "    },\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "          messages,\n",
        "          add_generation_prompt=True,\n",
        "          tokenize=True,\n",
        "          return_dict=True,\n",
        "          return_tensors=\"pt\",\n",
        "  ).to(model.device)\n",
        "\n",
        "  outputs = model.generate(**inputs, max_new_tokens=750, use_cache=False, do_sample=True, temperature=0.9, top_p=0.95,top_k=50)\n",
        "  response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KIbLXKPg239"
      },
      "outputs": [],
      "source": [
        "# Generate articles\n",
        "rng = np.random.default_rng()\n",
        "n = 4 # Number of datapoints to create\n",
        "for i in range(0, n + 1):\n",
        "  print(i)\n",
        "  # Get random num between 0 and length of list\n",
        "  random_integer = rng.integers(low=0, high=len(topics))\n",
        "  topic = topics[random_integer]\n",
        "  # Add unique identifier for the row\n",
        "  phi_df.loc[i, 'uuid'] = str(uuid.uuid4())\n",
        "  phi_df.loc[i, 'topic'] = topic\n",
        "  response = generate_article(topic)\n",
        "  phi_df.loc[i, 'generated_article'] = response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d3R9_4djedp"
      },
      "outputs": [],
      "source": [
        "phi_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxfk8Xqnjgtj"
      },
      "outputs": [],
      "source": [
        "phi_df.loc[3, 'generated_article']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWEcGCLmY52"
      },
      "outputs": [],
      "source": [
        "phi_df.to_csv(\"phi_outputs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHunOk8YQDa-"
      },
      "outputs": [],
      "source": [
        "## Load dataset\n",
        "# path = kagglehub.dataset_download(\"gowrishankarp/newspaper-text-summarization-cnn-dailymail\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)\n",
        "\n",
        "# train_df = pd.read_csv(path + \"/cnn_dailymail/train.csv\")\n",
        "# test_df = pd.read_csv(path + \"/cnn_dailymail/test.csv\")\n",
        "# val_df = pd.read_csv(path + \"/cnn_dailymail/validation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sx2YT5eQgYC"
      },
      "outputs": [],
      "source": [
        "## Loop through the train dataset\n",
        "# for index, row in train_df.head(1).iterrows():\n",
        "#   print(index)\n",
        "#   # Get article\n",
        "#   article = row[\"article\"]\n",
        "#   # Cut down to 100 words\n",
        "#   article = \" \".join(article.split()[:100])\n",
        "#   # Format the query\n",
        "#   messages = [\n",
        "#     {\n",
        "#         \"role\": \"user\",\n",
        "#         \"content\": [\n",
        "#             {\"type\": \"text\", \"text\": f\"Write a news article do not include a title\"}\n",
        "#             # {\"type\": \"text\", \"text\": f\"Write an article with a similar style to the following article example from CNN: {article}\"}\n",
        "#         ]\n",
        "#     },\n",
        "#   ]\n",
        "#   # Store query in df # TODO: Should happen in data cleaning?\n",
        "#   print(article)\n",
        "#   train_df.loc[index, 'query_article'] = messages[0]['content'][0]['text']\n",
        "#   ## Run query through inference\n",
        "#   inputs = processor.apply_chat_template(\n",
        "#     messages,\n",
        "#     add_generation_prompt=True,\n",
        "#     tokenize=True,\n",
        "#     return_dict=True,\n",
        "#     return_tensors=\"pt\",\n",
        "#   ).to(model.device)\n",
        "\n",
        "#   outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "#   response = processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
        "#   # Store answer in df\n",
        "#   train_df.loc[index, 'model_output'] = response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaVl5pXQo61d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}